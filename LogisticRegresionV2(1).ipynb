{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "phantom-finland",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\adri\\Documents\\TEC\\2023 II S\\patrones\\P1_Patrones\\LogisticRegresionV2(1).ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adri/Documents/TEC/2023%20II%20S/patrones/P1_Patrones/LogisticRegresionV2%281%29.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adri/Documents/TEC/2023%20II%20S/patrones/P1_Patrones/LogisticRegresionV2%281%29.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/adri/Documents/TEC/2023%20II%20S/patrones/P1_Patrones/LogisticRegresionV2%281%29.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimblearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mover_sampling\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomOverSampler\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adri/Documents/TEC/2023%20II%20S/patrones/P1_Patrones/LogisticRegresionV2%281%29.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adri/Documents/TEC/2023%20II%20S/patrones/P1_Patrones/LogisticRegresionV2%281%29.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurLogisticRegression (BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, lr=0.01, num_iter=100000, fit_intercept=True):\n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.fit_intercept = fit_intercept\n",
    "       \n",
    "\n",
    "    def __add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "\n",
    "    def __sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def __loss(self, h, y):\n",
    "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = self.__add_intercept(X)\n",
    "\n",
    "        # weights initialization\n",
    "        self.w = np.zeros(X.shape[1])\n",
    "\n",
    "        for i in range(self.num_iter):\n",
    "            z = np.dot(X, self.w)\n",
    "            h = self.__sigmoid(z)\n",
    "            gradient = np.dot(X.T, (h-y)) / y.size\n",
    "            #print(gradient.shape, self.w.shape, z.shape,h.shape)\n",
    "            #gradient = (h - y) / y.size\n",
    "            self.w -= self.lr * gradient\n",
    "\n",
    "    def predict_prob(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = self.__add_intercept(X)\n",
    "\n",
    "        return self.__sigmoid(np.dot(X, self.w))\n",
    "\n",
    "    def predict(self, X, threshold):\n",
    "        return self.predict_prob(X) >= threshold\n",
    "    \n",
    "    def score(self, y_pred,y_test):\n",
    "        return float(sum(y_pred == y_test)) / float(len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fae6a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0   1   25           1      49     91107       4    1.6          1         0   \n",
       "1   2   45          19      34     90089       3    1.5          1         0   \n",
       "2   3   39          15      11     94720       1    1.0          1         0   \n",
       "3   4   35           9     100     94112       1    2.7          2         0   \n",
       "4   5   35           8      45     91330       4    1.0          2         0   \n",
       "\n",
       "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0              0                   1           0       0           0  \n",
       "1              0                   1           0       0           0  \n",
       "2              0                   0           0       0           0  \n",
       "3              0                   0           0       0           0  \n",
       "4              0                   0           0       0           1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Bank_Personal_Loan_Modelling.csv\", encoding='latin-1')\n",
    "df.head()\n",
    "\n",
    "#X = np.array([[1,2],[1,3],[1,4],[1,5]])\n",
    "#y = np.array([[0],[0],[1],[1]])\n",
    "#ourRegression=LogisticRegression(alpha=0.01,iterations=10000)\n",
    "\n",
    "#w, J_history = ourRegression.gradient_descent(X, y)\n",
    "\n",
    "#print(\"W encontrado por gradiente descendente: \")\n",
    "#print(w)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-grain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Age', 'Experience', 'Income', 'ZIP Code', 'Family', 'CCAvg', 'Education', 'Mortgage', 'Personal Loan', 'Securities Account', 'CD Account', 'Online', 'CreditCard']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adri\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but PCA was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "features= df.columns.tolist()\n",
    "print(features)\n",
    "X=df[features]\n",
    "y = df[\"Personal Loan\"] \n",
    "\n",
    "# PUNTO 1 - MEJORAR EL ACCURACY \n",
    "\n",
    "# ESTANDARIZACION \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Calcula la matriz de covarianza\n",
    "cov_matrix = np.cov(X_scaled, rowvar=False)\n",
    "\n",
    "#PCA\n",
    "pca = PCA()\n",
    "pca.fit(cov_matrix)\n",
    "\n",
    "componentes_principales = pca.components_\n",
    "varianza_explicada = pca.explained_variance_ratio_\n",
    "\n",
    "varianza_acumulativa = np.cumsum(varianza_explicada)\n",
    "num_componentes_deseados = np.argmax(varianza_acumulativa >= 0.95) + 1  \n",
    "\n",
    "X_reduced = pca.transform(X)[:, :num_componentes_deseados]\n",
    "\n",
    "oversampler = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X_scaled, y)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_resampled,y_resampled,test_size=0.30,random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c7880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OurLogisticRegression()\n",
    "\n",
    "# fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Creamos un modelo de regresión logística\n",
    "#model = LogisticRegression()\n",
    "\n",
    "#model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fd6702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=OurLogisticRegression(),\n",
       "             param_grid={'fit_intercept': [True, False], 'lr': [0.01, 0.1, 1],\n",
       "                         'num_iter': [1000, 5000]})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# PUNTO 2\n",
    "# GRID SEARCH \n",
    "# Definimos la cuadrícula de hiperparámetros que queremos probar\n",
    "param_grid = {\n",
    "    'lr': [0.01, 0.1, 1],\n",
    "    'num_iter': [1000, 5000],\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=StratifiedKFold(n_splits=5))\n",
    "\n",
    "# búsqueda de hiperparámetros en el conjunto de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab55cc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "# predict probabilities for test set\n",
    "##probs = model.predict_prob(X_test)\n",
    "\n",
    "# predict classes for test set\n",
    "#y_pred = model.predict(X_test, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35078a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros encontrados:\n",
      "{'fit_intercept': True, 'lr': 0.01, 'num_iter': 1000}\n",
      "Precisión del mejor modelo entrenamiento: 0.9091428571428571\n",
      "Recall del mejor modelo: 0.0\n",
      "F1 Score del mejor modelo: 0.0\n",
      "Precisión del testing: 0.892\n"
     ]
    }
   ],
   "source": [
    "# mejores hiperparámetros encontrados\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(best_params)\n",
    "\n",
    "# mejor modelo entrenado\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "probs = best_model.predict_prob(X_test)\n",
    "y_pred = best_model.predict(X_test, threshold=0.5)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, best_model.predict(X_train, threshold=0.5))\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)  # Calcula el Recall\n",
    "f1 = f1_score(y_test, y_pred)  # Calcula el F1 Score\n",
    "\n",
    "print(\"Precisión del mejor modelo entrenamiento:\", train_accuracy)\n",
    "print(\"Recall del mejor modelo:\", recall)\n",
    "print(\"F1 Score del mejor modelo:\", f1)\n",
    "\n",
    "print(\"Precisión del testing:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecf6ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.892\n"
     ]
    }
   ],
   "source": [
    "#print(y_pred)\n",
    "#print(y_test)\n",
    "\n",
    "print(\"Precisión: \",best_model.score(y_pred,y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c306639ee32d404791473069f00ec2af6b0839684311cd4cb9a429487a8699f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
