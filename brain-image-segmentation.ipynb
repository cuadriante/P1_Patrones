{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Image Segmentation using UNet"]},{"cell_type":"markdown","metadata":{},"source":["## Import Libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:02:36.312503Z","iopub.status.busy":"2023-10-21T07:02:36.311633Z","iopub.status.idle":"2023-10-21T07:02:45.421927Z","shell.execute_reply":"2023-10-21T07:02:45.421094Z","shell.execute_reply.started":"2023-10-21T07:02:36.312469Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'tensorflow'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m/home/adri/Documents/invest_patrones/brain-image-segmentation.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adri/Documents/invest_patrones/brain-image-segmentation.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m#from skimage.morphology import label\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adri/Documents/invest_patrones/brain-image-segmentation.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/adri/Documents/invest_patrones/brain-image-segmentation.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adri/Documents/invest_patrones/brain-image-segmentation.ipynb#W2sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolor\u001b[39;00m \u001b[39mimport\u001b[39;00m rgb2gray\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adri/Documents/invest_patrones/brain-image-segmentation.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"]}],"source":["import os\n","import random\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","\n","plt.style.use(\"ggplot\")\n","%matplotlib inline\n","\n","import cv2\n","from tqdm import tqdm_notebook, tnrange\n","from glob import glob\n","from itertools import chain\n","from skimage.io import imread, imshow, concatenate_images\n","from skimage.transform import resize\n","#from skimage.morphology import label\n","from sklearn.model_selection import train_test_split\n","\n","import tensorflow as tf\n","from skimage.color import rgb2gray\n","from tensorflow.keras import Input\n","from tensorflow.keras.models import Model, load_model, save_model\n","from tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:02:48.894605Z","iopub.status.busy":"2023-10-21T07:02:48.893891Z","iopub.status.idle":"2023-10-21T07:02:49.022682Z","shell.execute_reply":"2023-10-21T07:02:49.0216Z","shell.execute_reply.started":"2023-10-21T07:02:48.894572Z"},"trusted":true},"outputs":[],"source":["DataPath = \"/lgg-mri-segmentation/kaggle_3m/\"\n","\n","dirs = []\n","images = []\n","masks = []\n","for dirname, _, filenames in os.walk(DataPath):\n","    for filename in filenames:\n","        if 'mask'in filename:\n","            dirs.append(dirname.replace(DataPath, ''))\n","            masks.append(filename)\n","            images.append(filename.replace('_mask', ''))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:02:50.248125Z","iopub.status.busy":"2023-10-21T07:02:50.247715Z","iopub.status.idle":"2023-10-21T07:02:50.254029Z","shell.execute_reply":"2023-10-21T07:02:50.252888Z","shell.execute_reply.started":"2023-10-21T07:02:50.248093Z"},"trusted":true},"outputs":[],"source":["print(masks[:10], images[:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:02:51.231641Z","iopub.status.busy":"2023-10-21T07:02:51.231012Z","iopub.status.idle":"2023-10-21T07:02:51.23902Z","shell.execute_reply":"2023-10-21T07:02:51.237974Z","shell.execute_reply.started":"2023-10-21T07:02:51.231605Z"},"trusted":true},"outputs":[],"source":["len(dirs), len(images), len(masks)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:02:52.52727Z","iopub.status.busy":"2023-10-21T07:02:52.526651Z","iopub.status.idle":"2023-10-21T07:02:52.536566Z","shell.execute_reply":"2023-10-21T07:02:52.535613Z","shell.execute_reply.started":"2023-10-21T07:02:52.527235Z"},"trusted":true},"outputs":[],"source":["imagePath_df = pd.DataFrame({'directory':dirs, 'images': images, 'masks': masks})"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:02:53.530153Z","iopub.status.busy":"2023-10-21T07:02:53.529501Z","iopub.status.idle":"2023-10-21T07:02:53.550466Z","shell.execute_reply":"2023-10-21T07:02:53.549364Z","shell.execute_reply.started":"2023-10-21T07:02:53.53012Z"},"trusted":true},"outputs":[],"source":["imagePath_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Image Shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:02:57.429433Z","iopub.status.busy":"2023-10-21T07:02:57.428533Z","iopub.status.idle":"2023-10-21T07:02:57.435465Z","shell.execute_reply":"2023-10-21T07:02:57.434472Z","shell.execute_reply.started":"2023-10-21T07:02:57.429398Z"},"trusted":true},"outputs":[],"source":["def print_imShape():\n","    idx = np.random.randint(0, len(imagePath_df))\n","    \n","    imagePath = os.path.join(DataPath, imagePath_df['directory'].iloc[idx], imagePath_df['images'].iloc[idx])\n","    maskPath = os.path.join(DataPath, imagePath_df['directory'].iloc[idx], imagePath_df['masks'].iloc[idx])\n","    \n","    image = cv2.imread(imagePath)\n","    mask = cv2.imread(maskPath)\n","    \n","    print(image.shape, mask.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:03:00.51217Z","iopub.status.busy":"2023-10-21T07:03:00.511765Z","iopub.status.idle":"2023-10-21T07:03:00.645541Z","shell.execute_reply":"2023-10-21T07:03:00.644494Z","shell.execute_reply.started":"2023-10-21T07:03:00.512138Z"},"trusted":true},"outputs":[],"source":["for i in range(5):\n","    print_imShape()"]},{"cell_type":"markdown","metadata":{},"source":["## Plot Images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:03:03.048216Z","iopub.status.busy":"2023-10-21T07:03:03.047834Z","iopub.status.idle":"2023-10-21T07:03:03.056201Z","shell.execute_reply":"2023-10-21T07:03:03.055208Z","shell.execute_reply.started":"2023-10-21T07:03:03.048186Z"},"trusted":true},"outputs":[],"source":["def plot_images():\n","    idx = np.random.randint(0, len(imagePath_df))\n","    \n","    imagePath = os.path.join(DataPath, imagePath_df['directory'].iloc[idx], imagePath_df['images'].iloc[idx])\n","    maskPath = os.path.join(DataPath, imagePath_df['directory'].iloc[idx], imagePath_df['masks'].iloc[idx])\n","    \n","    image = cv2.imread(imagePath)\n","    mask = cv2.imread(maskPath)\n","    \n","    fig, axs = plt.subplots(1,3, figsize=[13,15])\n","    \n","    axs[0].imshow(image)\n","    axs[0].set_title('Brain MRI')\n","    \n","    axs[1].imshow(mask)\n","    axs[1].set_title('Mask')\n","    \n","    axs[2].imshow(image)\n","    axs[2].imshow(mask, alpha=0.3)\n","    axs[2].set_title('MRI with mask')\n","    \n","    plt.grid(False)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:03:04.442713Z","iopub.status.busy":"2023-10-21T07:03:04.441814Z","iopub.status.idle":"2023-10-21T07:03:08.436678Z","shell.execute_reply":"2023-10-21T07:03:08.435678Z","shell.execute_reply.started":"2023-10-21T07:03:04.44268Z"},"trusted":true},"outputs":[],"source":["for i in range(5):\n","    plot_images()"]},{"cell_type":"markdown","metadata":{},"source":["Given the MRI Images of Brain our task is to identify if a tumor is present in the image or not. This problem boils down to image segmentation, which is extensively studied in the field of computer vision. Most popular use case is self driving cars\n","\n","Above figure shows a sneak peak of what the data looks like. We have Brain MRIs labeled with a mask which indicates the presence of abnormality"]},{"cell_type":"markdown","metadata":{},"source":["## Config"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:03:20.43986Z","iopub.status.busy":"2023-10-21T07:03:20.439126Z","iopub.status.idle":"2023-10-21T07:03:20.451904Z","shell.execute_reply":"2023-10-21T07:03:20.450859Z","shell.execute_reply.started":"2023-10-21T07:03:20.439801Z"},"trusted":true},"outputs":[],"source":["imagePath_df['image-path'] = DataPath + imagePath_df['directory'] + '/' + imagePath_df['images']\n","imagePath_df['mask-path'] = DataPath + imagePath_df['directory'] + '/' + imagePath_df['masks'] "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:03:21.682858Z","iopub.status.busy":"2023-10-21T07:03:21.682491Z","iopub.status.idle":"2023-10-21T07:03:21.693674Z","shell.execute_reply":"2023-10-21T07:03:21.69287Z","shell.execute_reply.started":"2023-10-21T07:03:21.682811Z"},"trusted":true},"outputs":[],"source":["train , test = train_test_split(imagePath_df, test_size=0.25, random_state=21)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:03:25.24897Z","iopub.status.busy":"2023-10-21T07:03:25.248206Z","iopub.status.idle":"2023-10-21T07:03:25.253515Z","shell.execute_reply":"2023-10-21T07:03:25.25237Z","shell.execute_reply.started":"2023-10-21T07:03:25.248936Z"},"trusted":true},"outputs":[],"source":["EPOCHS = 35\n","BATCH_SIZE = 32\n","ImgHieght = 256\n","ImgWidth = 256\n","Channels = 3"]},{"cell_type":"markdown","metadata":{},"source":["## Data Generator"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:03:27.208244Z","iopub.status.busy":"2023-10-21T07:03:27.207903Z","iopub.status.idle":"2023-10-21T07:03:27.213602Z","shell.execute_reply":"2023-10-21T07:03:27.212618Z","shell.execute_reply.started":"2023-10-21T07:03:27.20822Z"},"trusted":true},"outputs":[],"source":["data_augmentation = dict(rotation_range=0.2,\n","                        width_shift_range=0.05,\n","                        height_shift_range=0.05,\n","                        shear_range=0.05,\n","                        zoom_range=0.05,\n","                        horizontal_flip=True,\n","                        fill_mode='nearest')"]},{"cell_type":"markdown","metadata":{},"source":["### Train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:03:31.759441Z","iopub.status.busy":"2023-10-21T07:03:31.758576Z","iopub.status.idle":"2023-10-21T07:03:34.26285Z","shell.execute_reply":"2023-10-21T07:03:34.261946Z","shell.execute_reply.started":"2023-10-21T07:03:31.759406Z"},"trusted":true},"outputs":[],"source":["# image generator\n","imagegen = ImageDataGenerator(rescale=1./255., **data_augmentation)\n","maskgen = ImageDataGenerator(rescale=1./255., **data_augmentation)\n","\n","\n","# train generator\n","timage_generator=imagegen.flow_from_dataframe(dataframe=train,\n","                                            x_col=\"image-path\",\n","                                            batch_size= BATCH_SIZE,\n","                                            seed=42,\n","                                            class_mode=None,\n","                                            target_size=(ImgHieght,ImgWidth),\n","                                            color_mode='rgb')\n","# validation data generator\n","tmask_generator=maskgen.flow_from_dataframe(dataframe=train,\n","                                            x_col=\"mask-path\",\n","                                            batch_size=BATCH_SIZE,\n","                                            seed=42,\n","                                            class_mode=None,\n","                                            target_size=(ImgHieght,ImgWidth),\n","                                            color_mode='grayscale')    "]},{"cell_type":"markdown","metadata":{},"source":["### Validation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:03:38.436346Z","iopub.status.busy":"2023-10-21T07:03:38.435601Z","iopub.status.idle":"2023-10-21T07:03:39.407552Z","shell.execute_reply":"2023-10-21T07:03:39.406727Z","shell.execute_reply.started":"2023-10-21T07:03:38.43631Z"},"trusted":true},"outputs":[],"source":["# image generator\n","imagegen = ImageDataGenerator(rescale=1./255.)\n","maskgen = ImageDataGenerator(rescale=1./255.)\n","\n","\n","# train generator\n","vimage_generator=imagegen.flow_from_dataframe(dataframe=test,\n","                                            x_col=\"image-path\",\n","                                            batch_size= BATCH_SIZE,\n","                                            seed=42,\n","                                            class_mode=None,\n","                                            target_size=(ImgHieght,ImgWidth),\n","                                            color_mode='rgb')\n","# validation data generator\n","vmask_generator=maskgen.flow_from_dataframe(dataframe=test,\n","                                            x_col=\"mask-path\",\n","                                            batch_size=BATCH_SIZE,\n","                                            seed=42,\n","                                            class_mode=None,\n","                                            target_size=(ImgHieght,ImgWidth),\n","                                            color_mode='grayscale')    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:03:39.494926Z","iopub.status.busy":"2023-10-21T07:03:39.494574Z","iopub.status.idle":"2023-10-21T07:03:39.499747Z","shell.execute_reply":"2023-10-21T07:03:39.498861Z","shell.execute_reply.started":"2023-10-21T07:03:39.494898Z"},"trusted":true},"outputs":[],"source":["def data_iterator(image_gen, mask_gen):\n","    for img, mask in zip(image_gen, mask_gen):\n","        yield img, mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:03:43.139777Z","iopub.status.busy":"2023-10-21T07:03:43.139408Z","iopub.status.idle":"2023-10-21T07:03:43.144547Z","shell.execute_reply":"2023-10-21T07:03:43.143466Z","shell.execute_reply.started":"2023-10-21T07:03:43.139747Z"},"trusted":true},"outputs":[],"source":["train_gen = data_iterator(timage_generator, tmask_generator)\n","valid_gen = data_iterator(vimage_generator, vmask_generator)"]},{"cell_type":"markdown","metadata":{},"source":["## UNet"]},{"cell_type":"markdown","metadata":{},"source":["UNet is a fully convolutional neural-network. It got its name due to its U-shaped network architecture. It is currently SOTA in the sementic segmentation.\n","\n","What is semenctic segmentation?\n","\n","Well its a type of problem studied in computer vision just like image classification, object detection etc.\n","\n","*  **Image Classification:** We Iddentify what is present in an image. If it is present or not\n","\n","*  **Object Detection:** We identify what is present in the image and where it is present. Its sometimes also called object localization.\n","\n","*  **Image Segentation:** In object detection we identify position of an object by labeling a bounding box. In image segmentation we assign each pixel belongs to an image or not. There are two types of Image segmentation: Sementic segmentation and Instance segmentation.following image might help a little bit to visualize difference between these two"]},{"cell_type":"markdown","metadata":{},"source":["![](https://miro.medium.com/max/2454/1*cHtBw8yBhprNXj-CBQBx5g.png)"]},{"cell_type":"markdown","metadata":{},"source":["**Key aspects of UNet:**\n","\n","*  **Convolution Layers:** Convolution operation are used learn information from images which then can be used as features for mcahine learning problems\n","\n","*  **Down Sampling:** Sequence of convolution combined with max pooling results in down sampling. In down sampling Size of image is reduced which means we can observe larger portion of image in a single convolution operation. Down sampling is a good approach for identifying what is present in the image. but for identifying where the object is we need to use upsampling.\n","\n","*  **Up Sampling:** It is just opposite of down sampling. We go from low resolution to high resolution. For up sampling UNet uses transposed covolution which is achieved by taking transpose of filter kernels and reversing the process of convolution. If you want to learn more please check out [this](https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47) and [this](https://naokishibuya.medium.com/up-sampling-with-transposed-convolution-9ae4f2df52d0)."]},{"cell_type":"markdown","metadata":{},"source":["**Finally we come to UNet Architecture**\n","\n","Following picture gives a clear picture of What a UNet is. Since there are only convolution layers in this network, therefore its a FCN."]},{"cell_type":"markdown","metadata":{},"source":["![](http://miro.medium.com/max/2400/1*OkUrpDD6I0FpugA_bbYBJQ.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:03:57.683216Z","iopub.status.busy":"2023-10-21T07:03:57.682843Z","iopub.status.idle":"2023-10-21T07:03:57.690238Z","shell.execute_reply":"2023-10-21T07:03:57.68924Z","shell.execute_reply.started":"2023-10-21T07:03:57.683186Z"},"trusted":true},"outputs":[],"source":["def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n","    \n","    # first layer\n","    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n","              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n","    if batchnorm:\n","        x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    \n","    # second layer\n","    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n","              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n","    if batchnorm:\n","        x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    \n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:04:00.547182Z","iopub.status.busy":"2023-10-21T07:04:00.546789Z","iopub.status.idle":"2023-10-21T07:04:00.562306Z","shell.execute_reply":"2023-10-21T07:04:00.561411Z","shell.execute_reply.started":"2023-10-21T07:04:00.547155Z"},"trusted":true},"outputs":[],"source":["def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n","    \"\"\"Function to define the UNET Model\"\"\"\n","    # Contracting Path\n","    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n","    p1 = MaxPooling2D((2, 2))(c1)\n","    p1 = Dropout(dropout)(p1)\n","    \n","    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n","    p2 = MaxPooling2D((2, 2))(c2)\n","    p2 = Dropout(dropout)(p2)\n","    \n","    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n","    p3 = MaxPooling2D((2, 2))(c3)\n","    p3 = Dropout(dropout)(p3)\n","    \n","    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n","    p4 = MaxPooling2D((2, 2))(c4)\n","    p4 = Dropout(dropout)(p4)\n","    \n","    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n","    \n","    # Expansive Path\n","    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n","    u6 = concatenate([u6, c4])\n","    u6 = Dropout(dropout)(u6)\n","    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n","    \n","    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n","    u7 = concatenate([u7, c3])\n","    u7 = Dropout(dropout)(u7)\n","    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n","    \n","    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n","    u8 = concatenate([u8, c2])\n","    u8 = Dropout(dropout)(u8)\n","    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n","    \n","    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n","    u9 = concatenate([u9, c1])\n","    u9 = Dropout(dropout)(u9)\n","    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n","    \n","    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n","    model = Model(inputs=[input_img], outputs=[outputs])\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:04:04.338186Z","iopub.status.busy":"2023-10-21T07:04:04.337759Z","iopub.status.idle":"2023-10-21T07:04:09.69873Z","shell.execute_reply":"2023-10-21T07:04:09.697948Z","shell.execute_reply.started":"2023-10-21T07:04:04.338153Z"},"trusted":true},"outputs":[],"source":["input_img = Input((ImgHieght, ImgWidth, 3), name='img')\n","model = get_unet(input_img, n_filters=16, dropout=0.2, batchnorm=True)\n","model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:04:14.211317Z","iopub.status.busy":"2023-10-21T07:04:14.210658Z","iopub.status.idle":"2023-10-21T07:04:14.336152Z","shell.execute_reply":"2023-10-21T07:04:14.335217Z","shell.execute_reply.started":"2023-10-21T07:04:14.211281Z"},"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:04:26.930403Z","iopub.status.busy":"2023-10-21T07:04:26.929702Z","iopub.status.idle":"2023-10-21T07:04:26.936234Z","shell.execute_reply":"2023-10-21T07:04:26.935099Z","shell.execute_reply.started":"2023-10-21T07:04:26.930359Z"},"trusted":true},"outputs":[],"source":["callbacks = [\n","    EarlyStopping(patience=10, verbose=1),\n","    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=1e-5, verbose=1),\n","    ModelCheckpoint('model-brain-mri.h5', verbose=1, save_best_only=True, save_weights_only=True)\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:04:32.240922Z","iopub.status.busy":"2023-10-21T07:04:32.24051Z","iopub.status.idle":"2023-10-21T07:04:32.245451Z","shell.execute_reply":"2023-10-21T07:04:32.244233Z","shell.execute_reply.started":"2023-10-21T07:04:32.240892Z"},"trusted":true},"outputs":[],"source":["STEP_SIZE_TRAIN = timage_generator.n/BATCH_SIZE\n","STEP_SIZE_VALID = vimage_generator.n/BATCH_SIZE"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:04:34.826595Z","iopub.status.busy":"2023-10-21T07:04:34.825626Z","iopub.status.idle":"2023-10-21T07:44:00.081133Z","shell.execute_reply":"2023-10-21T07:44:00.08026Z","shell.execute_reply.started":"2023-10-21T07:04:34.826562Z"},"trusted":true},"outputs":[],"source":["results = model.fit(train_gen,\n","                    steps_per_epoch=STEP_SIZE_TRAIN,\n","                    batch_size=BATCH_SIZE,\n","                    epochs=EPOCHS,\n","                    callbacks=callbacks,\n","                    validation_data=valid_gen,\n","                   validation_steps=STEP_SIZE_VALID)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:44:25.071749Z","iopub.status.busy":"2023-10-21T07:44:25.071394Z","iopub.status.idle":"2023-10-21T07:44:25.433944Z","shell.execute_reply":"2023-10-21T07:44:25.432868Z","shell.execute_reply.started":"2023-10-21T07:44:25.07172Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(8, 8))\n","plt.title(\"Learning curve\")\n","plt.plot(results.history[\"loss\"], label=\"loss\", color=sns.xkcd_rgb['greenish teal'])\n","plt.plot(results.history[\"val_loss\"], label=\"val_loss\", color=sns.xkcd_rgb['amber'])\n","plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"log_loss\")\n","plt.legend()\n","# plt.grid(False)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:45:01.303705Z","iopub.status.busy":"2023-10-21T07:45:01.303321Z","iopub.status.idle":"2023-10-21T07:45:01.367531Z","shell.execute_reply":"2023-10-21T07:45:01.366606Z","shell.execute_reply.started":"2023-10-21T07:45:01.303674Z"},"trusted":true},"outputs":[],"source":["# load the best model\n","model.load_weights('model-brain-mri.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:45:05.669087Z","iopub.status.busy":"2023-10-21T07:45:05.668705Z","iopub.status.idle":"2023-10-21T07:45:10.210347Z","shell.execute_reply":"2023-10-21T07:45:10.209573Z","shell.execute_reply.started":"2023-10-21T07:45:05.669057Z"},"trusted":true},"outputs":[],"source":["eval_results = model.evaluate(valid_gen, steps=STEP_SIZE_VALID, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T07:45:32.751328Z","iopub.status.busy":"2023-10-21T07:45:32.750992Z","iopub.status.idle":"2023-10-21T07:45:41.770657Z","shell.execute_reply":"2023-10-21T07:45:41.769715Z","shell.execute_reply.started":"2023-10-21T07:45:32.751304Z"},"trusted":true},"outputs":[],"source":["for i in range(10):\n","    idx = np.random.randint(0, len(imagePath_df))\n","    \n","    imagePath = os.path.join(DataPath, imagePath_df['directory'].iloc[idx], imagePath_df['images'].iloc[idx])\n","    maskPath = os.path.join(DataPath, imagePath_df['directory'].iloc[idx], imagePath_df['masks'].iloc[idx])\n","    \n","    image = cv2.imread(imagePath)\n","    mask = cv2.imread(maskPath)\n","    \n","    img = cv2.resize(image ,(ImgHieght, ImgWidth))\n","    img = img / 255\n","    img = img[np.newaxis, :, :, :]\n","    pred=model.predict(img)\n","\n","    plt.figure(figsize=(12,12))\n","    plt.subplot(1,4,1)\n","    plt.imshow(np.squeeze(img))\n","    plt.title('Original Image')\n","    plt.subplot(1,4,2)\n","    plt.imshow(mask)\n","    plt.title('Original Mask')\n","    plt.subplot(1,4,3)\n","    plt.imshow(np.squeeze(pred))\n","    plt.title('Prediction')\n","    plt.subplot(1,4,4)\n","    plt.imshow(np.squeeze(pred) > 0.5)\n","    plt.title('BinaryPrediction')\n","    plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
