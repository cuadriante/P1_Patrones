{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:25<00:00, 6819528.01it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Transformations of data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize for CIFAR-10\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset and create dataloaders\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 32)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "all elements of target should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/adri/Downloads/Autoencoders.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adri/Downloads/Autoencoders.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adri/Downloads/Autoencoders.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m outputs \u001b[39m=\u001b[39m autoencoder(images)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/adri/Downloads/Autoencoders.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, images)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adri/Downloads/Autoencoders.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adri/Downloads/Autoencoders.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/torch/nn/modules/loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 618\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[0;32m~/myenv/lib/python3.11/site-packages/torch/nn/functional.py:3122\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3119\u001b[0m     new_size \u001b[39m=\u001b[39m _infer_size(target\u001b[39m.\u001b[39msize(), weight\u001b[39m.\u001b[39msize())\n\u001b[1;32m   3120\u001b[0m     weight \u001b[39m=\u001b[39m weight\u001b[39m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3122\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight, reduction_enum)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: all elements of target should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "autoencoder = Autoencoder()\n",
    "\n",
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "# Entrenamiento del autoencoder\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, _ in train_loader:\n",
    "        images = images.view(-1, 784)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = autoencoder(images)\n",
    "        loss = criterion(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    average_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}\")\n",
    "\n",
    "# Obtener las representaciones codificadas de los datos de entrenamiento\n",
    "encoded_imgs = []\n",
    "with torch.no_grad():\n",
    "    for images, _ in train_loader:\n",
    "        images = images.view(-1, 784)\n",
    "        encoded = autoencoder.encoder(images)\n",
    "        encoded_imgs.append(encoded)\n",
    "encoded_imgs = torch.cat(encoded_imgs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 32])\n",
      "tensor([[  6.5433,  -7.8309,  14.5471,  ...,  73.0008,  97.9721,  11.9257],\n",
      "        [ 33.9607,   3.8001,  -8.9526,  ...,   0.2264,  49.4532,  62.8196],\n",
      "        [ 53.2801, -17.2195,  20.3389,  ...,  67.6179, 116.5745,  -2.9910],\n",
      "        ...,\n",
      "        [ 38.3473,   4.7853, -32.7170,  ...,  24.7253,  72.2748,  57.5098],\n",
      "        [-31.2450,   5.0998, -26.7780,  ...,  15.9423,  56.6592,   6.8362],\n",
      "        [-15.4077,  10.3041, -12.5182,  ...,  61.3990,  48.8304,  15.7332]])\n"
     ]
    }
   ],
   "source": [
    "print(encoded_imgs.shape)\n",
    "print (encoded_imgs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizando la reconstrucción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "235/235 [==============================] - 7s 21ms/step - loss: 0.2397 - val_loss: 0.1631\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.1472 - val_loss: 0.1351\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.1307 - val_loss: 0.1233\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1209 - val_loss: 0.1163\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.1152 - val_loss: 0.1121\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.1112 - val_loss: 0.1080\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.1077 - val_loss: 0.1049\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.1047 - val_loss: 0.1024\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1024 - val_loss: 0.1002\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1005 - val_loss: 0.0985\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.0989 - val_loss: 0.0971\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0976 - val_loss: 0.0960\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.0965 - val_loss: 0.0952\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.0956 - val_loss: 0.0941\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.0948 - val_loss: 0.0934\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0940 - val_loss: 0.0930\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.0934 - val_loss: 0.0919\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0927 - val_loss: 0.0920\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0922 - val_loss: 0.0912\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0916 - val_loss: 0.0909\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0911 - val_loss: 0.0899\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0906 - val_loss: 0.0896\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.0901 - val_loss: 0.0893\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.0897 - val_loss: 0.0888\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0892 - val_loss: 0.0883\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.0888 - val_loss: 0.0881\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.0885 - val_loss: 0.0877\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0880 - val_loss: 0.0873\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.0876 - val_loss: 0.0868\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.0873 - val_loss: 0.0865\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0869 - val_loss: 0.0861\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.0867 - val_loss: 0.0858\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0864 - val_loss: 0.0858\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0861 - val_loss: 0.0855\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0859 - val_loss: 0.0855\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0857 - val_loss: 0.0850\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.0855 - val_loss: 0.0849\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.0853 - val_loss: 0.0849\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.0851 - val_loss: 0.0846\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.0849 - val_loss: 0.0843\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 5s 19ms/step - loss: 0.0847 - val_loss: 0.0841\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.0845 - val_loss: 0.0840\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0844 - val_loss: 0.0840\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0842 - val_loss: 0.0838\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0841 - val_loss: 0.0835\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0840 - val_loss: 0.0835\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0838 - val_loss: 0.0835\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0837 - val_loss: 0.0834\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0836 - val_loss: 0.0833\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0835 - val_loss: 0.0830\n",
      "313/313 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABiYAAAFECAYAAACjw4YIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAABJhklEQVR4nO3dd7gV1f0v/kFAiiBSxBIQBUSjRgVrsESNvRtLLFGjUWOPJZZEYyxR79XYklhzYyPWKHbj1xIVe6zYGwYB6VKko8D94/f8bjLzWeZsDnvPPhxer+fJH5/3s/achWedmdl7Zc+nxYIFCxZkAAAAAAAAJViq3hMAAAAAAACWHDYmAAAAAACA0tiYAAAAAAAASmNjAgAAAAAAKI2NCQAAAAAAoDQ2JgAAAAAAgNLYmAAAAAAAAEpjYwIAAAAAAChNq8a+cP78+dno0aOzjh07Zi1atKjmnFjMLFiwIJs2bVq28sorZ0stVbu9LmuO/2TdUbay1lyWWXf8m3Md9WDdUTbXWOrBuY56sO4om2ss9VDpumv0xsTo0aOznj17NvblNEMjR47MevToUbPjW3OkWHeUrdZrLsusOyLnOurBuqNsrrHUg3Md9WDdUTbXWOqhoXXX6K2yjh07NvalNFO1XhPWHCnWHWUrY01YdxQ511EP1h1lc42lHpzrqAfrjrK5xlIPDa2JRm9M+EoORbVeE9YcKdYdZStjTVh3FDnXUQ/WHWVzjaUenOuoB+uOsrnGUg8NrQnNrwEAAAAAgNLYmAAAAAAAAEpjYwIAAAAAACiNjQkAAAAAAKA0NiYAAAAAAIDS2JgAAAAAAABKY2MCAAAAAAAojY0JAAAAAACgNDYmAAAAAACA0tiYAAAAAAAAStOq3hOAJcUvf/nLkLVr1y5k6667bq7eZ599Kjr+tddem6tfeumlMGbQoEEVHQsAAAAAoFZ8YwIAAAAAACiNjQkAAAAAAKA0NiYAAAAAAIDS2JgAAAAAAABKo/k11MBdd90VskqbWBfNnz+/onE///nPc/W2224bxjz77LMhGzFiRKPmBSn9+vUL2YcffhiyX/ziFyH74x//WJM50XQts8wyufrSSy8NY4rntizLstdffz1X77vvvmHM559/voizAwAAllSdO3cO2SqrrNKoY6Xem5x88sm5+t133w1jPv7445ANHTq0UXOApsg3JgAAAAAAgNLYmAAAAAAAAEpjYwIAAAAAACiNjQkAAAAAAKA0ml9DFRSbXTe20XWWxUbB//M//xPG9O7dO2S77bZbru7Tp08Yc9BBB4Xs4osvXtgpwrfq379/yFIN3EeNGlXGdGjiVlpppVx95JFHhjGp9bPBBhvk6l133TWMufrqqxdxdixOBgwYELLBgweHbNVVVy1hNv/d9ttvn6s/+OCDMGbkyJFlTYfFSPFeL8uy7MEHHwzZ8ccfH7LrrrsuV8+bN696E6NmunfvHrK77747ZC+++GLIbrjhhlw9fPjwqs2rmjp16hSyLbfcMlc/9thjYczXX39dszkBzd8uu+ySq3ffffcwZquttgpZ3759G/XzUk2se/XqlavbtGlT0bFatmzZqDlAU+QbEwAAAAAAQGlsTAAAAAAAAKWxMQEAAAAAAJRGjwlYSBtuuGHI9tprrwZf995774Us9RzDiRMn5urp06eHMUsvvXTIXn755Vy93nrrhTFdu3ZtcJ6wKNZff/2QzZgxI2T33XdfCbOhKVl++eVDdsstt9RhJjRHO+ywQ8gqfU5v2Yp9Ag4//PAwZv/99y9rOjRhxfu2a665pqLX/elPfwrZjTfemKtnzZrV+IlRM507d87VqfcPqZ4M48aNC1lT7CmRmvvrr78esuI9Q7G3VJZl2aefflq9ibHQll122ZAVexeus846Ycy2224bMv1CWBTF3prHHXdcGJPqY9euXbtc3aJFi+pOrKBfv341PT4srnxjAgAAAAAAKI2NCQAAAAAAoDQ2JgAAAAAAgNLYmAAAAAAAAEqzWDW/3meffUKWamIzevToXD179uww5rbbbgvZ2LFjQ6apFkUrrbRSyIqNklKN6lKNOceMGdOoOZx66qkhW2uttRp83SOPPNKonwffptjU7vjjjw9jBg0aVNZ0aCJOPPHEkO25554h23jjjavy87bccsuQLbVU/P9eDB06NGRDhgypyhwoT6tW8fZ15513rsNMGqfY6PWUU04JY5ZZZpmQzZgxo2Zzomkqntt69OhR0evuuOOOkKXeD1Ff3bp1C9ldd92Vq7t06RLGpJqgn3DCCdWbWA2dffbZIVtttdVC9vOf/zxXe09eXwcddFDILrzwwpD17NmzwWOlmmZ/+eWXjZsYZPHa+Itf/KJOM/m3Dz/8MGSpz4hoPvr27Ruy1HV+r732ytVbbbVVGDN//vyQXXfddSF74YUXcvXieq30jQkAAAAAAKA0NiYAAAAAAIDS2JgAAAAAAABKY2MCAAAAAAAozWLV/PqSSy4J2aqrrtqoYxUbamVZlk2bNi1kTbFBzahRo0KW+m/z2muvlTGdJc5DDz0UsmKjm9RamjRpUtXmsP/++4esdevWVTs+VGrNNdfM1amGrcVGjjR/V1xxRchSTbyq5Uc/+lFF2eeffx6yH//4x7m62JiYpmfrrbcO2fe///2Qpe6NmoLOnTvn6rXWWiuMad++fcg0v27e2rRpE7KzzjqrUccaNGhQyBYsWNCoY1E7AwYMCFmqCWbR+eefX4PZ1Mbaa6+dq0899dQw5r777guZe8f6KTYSzrIsu/LKK0PWtWvXkFVynvnjH/8YsuOPPz5XV/N9M01TsSlwqmF1sbFvlmXZY489FrI5c+bk6qlTp4YxqXuo4vvWxx9/PIx59913Q/bKK6+E7M0338zVs2bNqmgOLB7WWWedkBXPW6n3nqnm1421ySabhOybb77J1R999FEY8/zzz4es+Pc2d+7cRZzdovGNCQAAAAAAoDQ2JgAAAAAAgNLYmAAAAAAAAEqzWPWYOPLII0O27rrrhuyDDz7I1d/97nfDmEqf6bnpppvm6pEjR4YxPXv2DFklis8Dy7IsmzBhQshWWmmlBo81YsSIkOkxUZ7Uc8ur5bTTTgtZv379Gnxd6tmHqQwWxemnn56rU38LzkXN26OPPhqypZaq7f/v4csvv8zV06dPD2N69eoVstVWWy1k//znP3N1y5YtF3F2VFvxua533HFHGDNs2LCQXXTRRTWb06LYY4896j0FmqDvfe97Idtggw0afF3q/cTf//73qsyJ6unevXvI9t577wZf97Of/SxkqfeLTUGxn0SWZdmTTz7Z4OtSPSZS/fooxy9/+cuQdenSpWrHL/b2yrIs23HHHXP1hRdeGMakelPU+7noVCbVg7DYz2G99dYLY/baa6+Kjv/yyy/n6tRnfcOHDw/ZKquskqtTvVxr2SOP+kt9nnzccceFLHXeWnbZZRs8/hdffBGy5557Llf/61//CmOKn7FkWboP4sYbb5yrU+fqnXfeOWRDhw7N1dddd10YUybfmAAAAAAAAEpjYwIAAAAAACiNjQkAAAAAAKA0NiYAAAAAAIDSLFbNr5966qmKsqLHHnusouN37tw5ZOuvv36uTjUc2WijjSo6ftHs2bND9vHHH4es2Mw71dAk1fSRxdOuu+6aq88///wwZumllw7Z+PHjc/WvfvWrMGbmzJmLODuWZKuuumrINtxww1ydOofNmDGjVlOiDn7wgx/k6jXWWCOMSTWKa2zzuFQzrmLDvKlTp4Yx22yzTcjOOuusBn/eMcccE7Jrr722wddRO2effXauTjVRLDbOzLJ0U/Sype7Zin9DGiuSZZU1Qk4png9pmi677LKQ/eQnPwlZ8b3m3/72t5rNqdq22GKLkK2wwgq5+uabbw5j/vrXv9ZqSlSgV69eufqwww6r6HVvv/12yMaNG5ert91224qO1alTp1ydasB92223hWzs2LEVHZ/ypD6nuP3220NWbHZ90UUXhTFPPvlko+aQanSdMmLEiEYdn8XX9ddfn6tTDda7detW0bGKn0W/8847Ycyvf/3rkKU+By4aOHBgyFLvUW+88cZcXfz8OsvieTnLsuzqq6/O1ffee28YM2HChIamWTW+MQEAAAAAAJTGxgQAAAAAAFAaGxMAAAAAAEBpbEwAAAAAAAClWayaX9fa5MmTQ/b00083+LpKGnBXKtX4rtiUO9VU5a677qraHKivYjPhVAOplOIaePbZZ6s2J8iy2LA1pcwmSdRequH5nXfemasrbRCW8vnnn+fqVOOt8847L2QzZ85c6GNnWZYdddRRIVt++eVz9SWXXBLGtG3bNmR/+tOfcvXXX3/d4Jxo2D777BOynXfeOVd/+umnYcxrr71WszktilTD9WKz62eeeSaMmTJlSo1mRFO15ZZbNjhm7ty5IUutMZqeBQsWhCzV+H706NG5OvU7L1u7du1Clmroeeyxx4as+O8+/PDDqzcxqqLYLLVjx45hzHPPPRey1PuC4v3SAQccEMak1k6fPn1y9YorrhjGPPDAAyHbaaedQjZp0qSQUTsdOnTI1b/61a/CmF133TVkEydOzNW///3vw5hK7vchy9Lv1U4//fSQHXHEEbm6RYsWYUzq84xrr702ZJdeemmunjFjRoPzrFTXrl1D1rJly5Cde+65ufqxxx4LY3r16lW1edWKb0wAAAAAAAClsTEBAAAAAACUxsYEAAAAAABQGhsTAAAAAABAaTS/rqPu3buH7JprrgnZUkvl94/OP//8MEaTp8XT/fffH7Ltt9++wdfdeuutITv77LOrMSX4Vt/73vcaHJNqHMziq1WreJvQ2GbXzz77bMj233//XF1shLcoUs2vL7744pBdfvnlubp9+/ZhTGpdP/jgg7l62LBhCztFEvbdd9+QFX8nqXulpiDVLP6ggw4K2bx583L17373uzBGM/XmbeDAgRVlRanGim+99VY1pkQTscsuu+Tqxx9/PIyZMmVKyFKNORur2NR4q622CmM23XTTio51zz33VGNK1FCbNm1ydapR+xVXXFHRsWbPnp2rb7rppjAmdZ3v3bt3g8dONUJuCs3hl3R77rlnrj7zzDPDmBEjRoRsiy22yNVTp06t6rxYsqSuU6eddlrIis2uv/jiizBm7733Dtk///nPxk+uoNjEumfPnmFM6vO+Rx99NGSdO3du8OelGnwPGjQoV6fuK8rkGxMAAAAAAEBpbEwAAAAAAAClsTEBAAAAAACURo+JOjruuONCtvzyy4ds8uTJufqjjz6q2ZyonZVWWilkqecJF5/zmXrmeup51NOnT1+E2UFe6tnBhx12WMjefPPNXP3EE0/UbE4sPl577bWQHX744SGrZk+JShT7QmRZ7AGw0UYblTWdJV6nTp1CVslzy6v5LPVqOuqoo0KW6snywQcf5Oqnn366ZnOiaWrseaaprn0adtVVV4Vs6623DtnKK6+cq7fccsswJvW86N13330RZvffj5/qOZDy2WefhezXv/51VeZE7RxwwAENjin2PsmydK/ESmy44YaNet3LL78cMu9/66+S/kjF94tZlmWjRo2qxXRYQhX7NmRZ7OmW8s0334Rsk002Cdk+++wTsjXXXLPB48+aNStk3/3ud/9rnWXp98grrLBCgz8vZdy4cSErfp5Y7952vjEBAAAAAACUxsYEAAAAAABQGhsTAAAAAABAaWxMAAAAAAAApdH8uiSbbbZZyM4888yKXrvnnnvm6nfffbcaU6Jk9957b8i6du3a4Ov++te/hmzYsGFVmRN8m2233TZkXbp0Cdljjz2Wq2fPnl2zOdE0LLVUw/+fhlTTsKYg1TC0+O+p5N+XZVl27rnn5uqDDz640fNaUrVp0yZk3/nOd0J2xx13lDGdRdanT5+KxrmPo9Lmr1OmTMnVml8vvl5//fWQrbvuuiFbf/31c/WOO+4Yxpx22mkhmzBhQshuueWWhZjhvw0aNChXDx06tKLXvfjiiyHznqXpK15jU43UN9poo5ClGr9+73vfy9V77bVXGNO5c+eQFc91qTFHHnlkyIprNcuy7P333w8ZtZNqClyUOo/99re/zdUPPPBAGPPWW281el4sWf7xj3+E7Omnnw5Z8TOOVVZZJYz5wx/+ELIFCxY0OIdUs+1UU+5KVNroev78+bn6vvvuC2NOPPHEkI0ZM6ZR86oV35gAAAAAAABKY2MCAAAAAAAojY0JAAAAAACgNDYmAAAAAACA0mh+XZKdd945ZK1btw7ZU089FbKXXnqpJnOidlJNwwYMGFDRa5955plcXWwMBWVYb731QpZq+nTPPfeUMR3q5Oijjw5ZscnW4mS33XYLWf/+/XN16t+XyorNr1l406ZNC1mq0WGxQWyXLl3CmEmTJlVtXpXo3r17yCppAJllWfb8889Xezo0cZtvvnmuPvDAAyt63dSpU3P1qFGjqjYn6m/y5MkhKzbrTDXvPOOMM2o2pyzLst69e+fqFi1ahDGpc/Uvf/nLWk2JGnryySdzdfG8k2WxqXWWpZtMV9IgtvjzsizLjjvuuFz98MMPhzGrr756yFJNXVP3rtTO8ssvn6tT98xt2rQJ2TnnnJOrzz777DDmuuuuC9nLL78csmID408//TSMee+990JWtPbaa4cs9Vmca3HTM2vWrJDttddeIVtuueVy9ZlnnhnGbLbZZiH78ssvQzZixIhcnVrnqc9UNt5445A11g033JCrf/3rX4cxU6ZMqdrPqxXfmAAAAAAAAEpjYwIAAAAAACiNjQkAAAAAAKA0ekzUSLt27XL1jjvuGMbMnTs3ZKl+Al9//XX1JkZNdO3aNVennu2W6imSUnxm6/Tp0xs9L6jUiiuumKu32GKLMOajjz4K2X333VezOVF/qZ4MTVHx+bZZlmVrrbVWyFLn5kpMmDAhZK7Niy71PNhhw4aFbO+9987VjzzySBhz+eWXV21e66yzTsiKz1xfddVVw5hKnq2dZYt3nxYap3ifuNRSlf1/w5544olaTAf+q+Kz31PntlSfi9S1kqav2KNpv/32C2NSPeU6derU4LH/+Mc/hiy1dmbPnp2rBw8eHMakngW/ww47hKxPnz65OnVfQfX8/ve/z9WnnHJKo46Tui4ee+yxFWW1lDqvFXuCZlmW7b///iXMhkVV7LeQOq9U06233hqySnpMpPrwpf62br755lw9b968yifXhPjGBAAAAAAAUBobEwAAAAAAQGlsTAAAAAAAAKWxMQEAAAAAAJRG8+saOe2003J1//79w5jHHnssZC+++GLN5kTtnHrqqbl6o402quh1999/f8hSDdCh1n7605/m6u7du4cxf//730uaDSycs846K2THHXdco441fPjwkB166KEhGzFiRKOOz3+Xuga2aNEiV++yyy5hzB133FG1OUycODFkxeav3bp1a/Txi43qaP722WefBscUGzJmWZZdf/31NZgN/Nu+++4bskMOOSRXp5pwfvnllzWbE/X15JNPhix1DjvwwANDVjyPFRupZ1lsdJ1ywQUXhOy73/1uyHbfffeQFX9m6h6O6ik2D77rrrvCmNtvvz1krVrlP4rs2bNnGJNqiF225ZdfPmSpv4ezzz47V//ud7+r2Zxomk4//fSQNbYp+tFHHx2yar7XaWrq/5cOAAAAAAAsMWxMAAAAAAAApbExAQAAAAAAlMbGBAAAAAAAUBrNr6sg1YTxN7/5Ta7+6quvwpjzzz+/ZnOiXKecckqjXnf88ceHbPr06Ys6HVhovXr1anDM5MmTS5gJNOzRRx/N1WussUbVjv3++++H7Pnnn6/a8fnvPvzww5Dtt99+uXr99dcPY/r27Vu1Odxzzz0NjrnllltCdtBBB1V0/FmzZi30nFh89OjRI2SpJrFFo0aNCtlrr71WlTnBt9lpp50aHPPwww+H7I033qjFdGiiUg2xU1m1pK6TqabKqebXW2+9da7u0qVLGDNp0qRFmB3/ad68ebk6dd3q169fg8f54Q9/GLLWrVuH7Nxzzw3ZRhtt1ODxq6lFixYh22CDDUqdA/V3xBFH5OpiA/Qsi03eU957772QDR48uPETWwz5xgQAAAAAAFAaGxMAAAAAAEBpbEwAAAAAAAClsTEBAAAAAACURvPrhdS1a9eQ/eEPfwhZy5Ytc3WxUWeWZdnLL79cvYmxWEo14/r666+rcuypU6dWdOxUU6lOnTo1ePzlllsuZI1tAl5smpVlWXbGGWfk6pkzZzbq2FRm1113bXDMQw89VMJMaEpSzd2WWqrh/09DJc00syzLbrjhhly98sorV/S64hzmz59f0esqsdtuu1XtWNTGW2+9VVFWS5999lmjX7vOOuvk6nfffXdRp0MTMnDgwJBVct68//77azAb+O9S1+sZM2bk6ssuu6ys6cC3uvvuu0OWan794x//OFcff/zxYcz5559fvYlRFU899VRF49Zff/2QFZtff/PNN2HMTTfdFLI///nPufqkk04KYw488MCK5kXztvHGG4eseG3s0KFDRceaPn16rj766KPDmDlz5izE7BZ/vjEBAAAAAACUxsYEAAAAAABQGhsTAAAAAABAafSYaECxV8Rjjz0Wxqy22mohGzZsWK7+zW9+U92J0Sy8/fbbNTv23/72t5CNGTMmZCussELIis/mrIexY8fm6gsvvLBOM2l+Nt9885CtuOKKdZgJTd21114bsksuuaTB1z388MMhq6QPRGN7RSxKj4nrrruu0a9lyZXqv5LKUvSUaN5S/eiKJk6cGLKrrrqqFtOB/yf1HOvU+4Dx48fn6jfeeKNmc4JKpe71Uveke+yxR67+7W9/G8bceeedIfv4448XYXaU5fHHHw9Z8XOCVq3ix5xHHnlkyPr27Zurt9pqq0bPa9SoUY1+LU1fqgdhx44dG3xdsWdTlsXeOC+88ELjJ9ZM+MYEAAAAAABQGhsTAAAAAABAaWxMAAAAAAAApbExAQAAAAAAlEbz6wb06dMnV2+wwQYVve6UU07J1cVm2DQvjz76aK4uNt2qh3333bdqx/rmm29CVkmz2QcffDBkr732WkU/87nnnqtoHAtvr732ClnLli1z9ZtvvhnGDBkypGZzomkaPHhwyE477bRcvfzyy5c1nW81YcKEkH3wwQchO+qoo0I2ZsyYmsyJ5m3BggUVZSx5dthhhwbHjBgxImRTp06txXTg/0k1v06dtx555JEGj5Vq+tm5c+eQpdY6VMtbb70VsnPOOSdXX3rppWHMRRddFLKDDz44V8+aNWvRJkdNpO7v77777ly93377VXSsrbfeusEx8+bNC1nqHHnmmWdW9DNp+lLXt9NPP71Rx7rttttC9swzzzTqWM2Zb0wAAAAAAAClsTEBAAAAAACUxsYEAAAAAABQGhsTAAAAAABAaTS//g+9evUK2eOPP97g64qNQLMsyx5++OGqzInFw49+9KNcnWqO07p160Yde+211w7Zj3/840Yd68YbbwzZ8OHDG3zdvffeG7IPP/ywUXOgXO3btw/Zzjvv3ODr7rnnnpClmn/RvH3++ech23///XP1nnvuGcb84he/qNWUki688MKQXX311aXOgSVL27ZtKxqneWbzlrq369OnT4Ovmz17dsi+/vrrqswJFlXxfu+ggw4KY04++eSQvffeeyE79NBDqzcxqMCtt96aq3/+85+HMcX37lmWZeeff36ufvvtt6s7MaoidV910kkn5eoOHTqEMRtuuGHIunfvnqtTn4sMGjQoZOeee+5/nySLjdRaef/990NWyWd5qXNGcW2S5hsTAAAAAABAaWxMAAAAAAAApbExAQAAAAAAlEaPif9w1FFHhWyVVVZp8HXPPvtsyBYsWFCVObF4uuSSS2p6/AMPPLCmx6f5SD2zevLkySF78MEHc/VVV11VszmxeBsyZMh/rbMs3Z8pdY3dbbfdcnVxHWZZlt1www0ha9GiRa5OPQsUaumwww4L2ZQpU0J2wQUXlDAb6mX+/Pkhe+2110K2zjrr5OpPP/20ZnOCRXXEEUfk6p/97GdhzF/+8peQOd/RFEyYMCFXb7vttmFMqpfAGWeckatTvVVomsaNG5eri+8vsizLDj744JBtuummufq8884LY8aPH7+Is6Mp22abbULWo0ePkFXy+W6q91KqpxiRb0wAAAAAAAClsTEBAAAAAACUxsYEAAAAAABQGhsTAAAAAABAaZbY5tebb755yE444YQ6zASgdlLNrwcOHFiHmbAkeeyxxyrKYHH16quvhuzyyy8P2dNPP13GdKiTefPmheyss84KWbFp4uuvv16zOcG3Of7440N2/vnnh2zIkCG5+tprrw1jJk+eHLK5c+cuwuygNkaMGBGyJ598MmS77757rl5rrbXCmPfff796E6NUgwYNqihjyXLBBReErJJG11mWZZdeemmuds/feL4xAQAAAAAAlMbGBAAAAAAAUBobEwAAAAAAQGlsTAAAAAAAAKVZYptfb7HFFiHr0KFDg68bNmxYyKZPn16VOQEA0PTttttu9Z4CTdTo0aNDdvjhh9dhJpD3/PPPh2ybbbapw0ygvvbZZ5+QDR06NFf37ds3jNH8GpqXLl26hKxFixYhGz9+fMiuvPLKWkxpieQbEwAAAAAAQGlsTAAAAAAAAKWxMQEAAAAAAJTGxgQAAAAAAFCaJbb5daWKTZB++MMfhjGTJk0qazoAAAAANMJXX30VstVWW60OMwHq6fLLL68ou+CCC0I2ZsyYmsxpSeQbEwAAAAAAQGlsTAAAAAAAAKWxMQEAAAAAAJRmie0xcfHFF1eUAQAAAADQPFxxxRUVZdSWb0wAAAAAAAClsTEBAAAAAACUxsYEAAAAAABQmkZvTCxYsKCa86AZqPWasOZIse4oWxlrwrqjyLmOerDuKJtrLPXgXEc9WHeUzTWWemhoTTR6Y2LatGmNfSnNVK3XhDVHinVH2cpYE9YdRc511IN1R9lcY6kH5zrqwbqjbK6x1ENDa6LFgkZuZ82fPz8bPXp01rFjx6xFixaNmhzNw4IFC7Jp06ZlK6+8crbUUrV7Opg1x3+y7ihbWWsuy6w7/s25jnqw7iibayz14FxHPVh3lM01lnqodN01emMCAAAAAABgYWl+DQAAAAAAlMbGBAAAAAAAUBobEwAAAAAAQGlsTAAAAAAAAKWxMQEAAAAAAJTGxgQAAAAAAFAaGxMAAAAAAEBpbEwAAAAAAAClsTEBAAAAAACUxsYEAAAAAABQGhsTAAAAAABAaWxMAAAAAAAApbExAQAAAAAAlMbGBAAAAAAAUBobEwAAAAAAQGlsTAAAAAAAAKWxMQEAAAAAAJTGxgQAAAAAAFAaGxMAAAAAAEBpbEwAAAAAAAClsTEBAAAAAACUxsYEAAAAAABQGhsTAAAAAABAaWxMAAAAAAAApbExAQAAAAAAlMbGBAAAAAAAUBobEwAAAAAAQGlsTAAAAAAAAKWxMQEAAAAAAJTGxgQAAAAAAFAaGxMAAAAAAEBpbEwAAAAAAAClsTEBAAAAAACUplVjXzh//vxs9OjRWceOHbMWLVpUc04sZhYsWJBNmzYtW3nllbOllqrdXpc1x3+y7ihbWWsuy6w7/s25jnqw7iibayz14FxHPVh3lM01lnqodN01emNi9OjRWc+ePRv7cpqhkSNHZj169KjZ8a05Uqw7ylbrNZdl1h2Rcx31YN1RNtdY6sG5jnqw7iibayz10NC6a/RWWceOHRv7UpqpWq8Ja44U646ylbEmrDuKnOuoB+uOsrnGUg/OddSDdUfZXGOph4bWRKM3Jnwlh6JarwlrjhTrjrKVsSasO4qc66gH646yucZSD8511IN1R9lcY6mHhtaE5tcAAAAAAEBpbEwAAAAAAAClsTEBAAAAAACUxsYEAAAAAABQGhsTAAAAAABAaWxMAAAAAAAApbExAQAAAAAAlMbGBAAAAAAAUBobEwAAAAAAQGlsTAAAAAAAAKVpVe8JQHO07LLLhuzwww8P2cEHHxyyPn365OpJkyaFMXPnzg3Z+PHjc/Vvf/vbMOa5554L2TfffBMyqKallop74AsWLKgoY8nSqlW8LenatWvIimtq7NixYYz1BAAANFUtWrT4r3WWZdn8+fPLmg7UhW9MAAAAAAAApbExAQAAAAAAlMbGBAAAAAAAUBobEwAAAAAAQGk0v4aFlGrku8oqq+TqSy65JIzZZpttQpZqkt2yZcsGx6Sauq622mq5+tJLLw1j9thjj5B98cUXIYNKFRt0bbzxxmHM8ccfH7K//e1vIXvooYdytebFzUuqmVv//v1z9U033RTGdOnSJWQffPBBrj7mmGPCmGHDhi3sFFmMFa+dWZZec8XzSqqhYCXnntSxU1nqnqEoNQeNDqlUmzZtQjZv3ryQffPNN2VMBwCatVat4seoyyyzTK4eMGBAGLPiiiuG7JNPPsnVG220URjzj3/8I2QfffRRg/OExYVvTAAAAAAAAKWxMQEAAAAAAJTGxgQAAAAAAFAaGxMAAAAAAEBpNL+GhVRsdJ1lWXb++efn6m233TaM6dChQ8hmzZoVsunTp+fqSZMmhTFt27YNWbGZUt++fcOY7bbbLmQ333xzyKBSxbW4++67hzE/+MEPQvbGG2/UbE40TUsvvXTIik2re/fuHcakmgf36dMnV6+11lphjObXzVdqLa288sohSzUnnDlzZq6eMmVKGDN37tyQNbYhdmqunTp1ytWppsSpa3+qoTHNW3FN9e/fP4y55ZZbQvbWW2+F7Kc//Wmutp7qL3XOaN++fa7edNNNw5jUdfGll14KWfF9Rj1+58V/Y7t27cKYfv36hax4bh4xYkQYM3/+/EWbHNAsFM8zqXNk8dyaZVm20korNThm9dVXD9lOO+0Usj333DNXF5thf5viefqaa64JY1Ln7pYtW1Y0DhYHvjEBAAAAAACUxsYEAAAAAABQGhsTAAAAAABAaZp0j4nis4FTz4pLPVvt66+/ztWpZ/dCJVLPQT3ooINCtvbaa+fq1LOoX3zxxZD97//9v0P2yiuv5OpUH4pll102ZMVnDG+22WZhzOmnnx6yW2+9NWSe2UqlWrdunatTz/pPPa/9kUceCVklz3Bn8ZB6bvYhhxwSsuL5NPU8/tS66NatW64+8cQTw5jUM9ZHjhwZMhY/qef2pp69P23atJB9+umnuTrVh6KxPSZS2rRpE7KBAwfm6tS97N///veQpf49NG/LLbdcrr7zzjvDmGLPnSyLfUyyLL6P8izqcqX+zou/3yzLst/85je5etdddw1jPvnkk5Clnkv+8ssv5+qpU6eGMcX3zVlW3fux4nuW1HuRrbbaKmT33HNPrv7zn/8cxhT78lGu1D1bsVdYqsfiZ599FrJiTxHvRcmy9PuJ1H1bsVfEkUceGcZsv/32ISv25Cy+r82y9H1c6nPJYpaaeyVZsVdFlmXZU089FbIvvvgiZKnPjWj6UusppTmfF31jAgAAAAAAKI2NCQAAAAAAoDQ2JgAAAAAAgNLYmAAAAAAAAErTZJpfpxqCFZvR7LHHHmFMselwlmXZ559/nqvfeeedMGb06NEhKzZdSkmNmThxYsiKTcNSTXpSjZVTjU9mz56dq1NNbVKNy1h0qQZFzz77bMjatm2bq1ONaf7yl7+ELNW0qJJmhKmG7l27ds3VqfWVaoYIi6Jnz565ul+/fmFMqvF7sQEtzcs222wTsj/+8Y8hKzaUSzXcTJ1Pi82Pt9xyyzDm+eefD9nmm28eMg2xm77ivdHGG28cxqSaBQ4ZMiRkxaboM2bMCGMa2xQ4dc+QOlaxGWyXLl3CmFRTUZY8xcbHq666ahiTWnejRo0KWerekfKk3uOlmj7/4Ac/yNWp+/mxY8eGLNUQ+6uvvsrVtW50nbLCCivk6t122y2MSf0b586dm6tnzpxZ3YmxULp16xay22+/PWQDBgzI1XPmzAljPv7445D97Gc/y9WpBtk0b6lzZMeOHUO23XbbheyQQw7J1ZtttlkYU3zvkGXxM8jUPVvqGlv8fC7L4md0EyZMCGNS/8bi38Nll10Wxrz66qsVzYFyFdfP8ssvH8ZsuOGGITvvvPNydffu3cOY1OfO99xzT8geeOCBXJ26/0sdq7jWa30v0BDfmAAAAAAAAEpjYwIAAAAAACiNjQkAAAAAAKA0NiYAAAAAAIDSNJnm16lGMEWpxjNrrrlmyPr375+r999//zCmQ4cOIUs1xC4246q0MWexGXL79u0bPPa3KTa2eeaZZ8KYY489NmSVNPPmv0s1FSo2zsyyLPvwww9zdapxUmMbbKbW/XrrrReyNdZYI1en/qZSc0+tX0hJrcVi0+FUY7H33nsvZNZd89GrV6+Q3X333SErNrpOqbTxVnEtphoF9+jRI2SPPvpoyDbYYINcXWy4Sf0VzyuHHnpoGJNqCnz99deHrHhv1NhG15VKnRP79euXq1P3pKkmtTRvxSaKWZZlRxxxRINjUgYNGhSyejc2JFpttdVCVnwP+dFHH4UxqabDw4YNC1mx4Xmt10BqfRab0H7nO98JYz799NOQFf+N7hvLk/odPffccyFL3f8V33+m1lzqc5GTTjopV59++ulhjGa/zUurVvmPIldeeeUwZpdddgnZKqusErLiueeTTz4JY5ZddtmQFRtU//nPfw5jlltuuZCNGDEiZC+//HKuTn0WVzwnpzjX1V/qHFX8jDnLsuzkk0/O1alG16nzaXHtp86TK664YsiOOeaYkO2xxx65eurUqWHMkCFDQnbLLbfk6tSaTr1HqtV9hG9MAAAAAAAApbExAQAAAAAAlMbGBAAAAAAAUJom02Mi9by14vMmb7rppjBmzpw5Idtzzz1zdfFZnVmWZV999VXIJk6cGLJu3brl6tSzglPP/2rdunWuTj0rOPUc644dO4as+Ozh7bffPoxJ9dooPueOhZd6xt/06dNDVuwfkervkMqKz5dLjVt33XXDmMGDB4es2LMk1dNir732ChlUKvW8xUMOOSRXp863//M//1OzOVG+4nXq4YcfDmO6dOnSqGOnzrmp62exx0TqXJrqiZLqQ3Deeefl6t/+9rdhjL4T5Un93n7yk5/k6h/+8IdhzPDhw0NWyTPXqyl1nR8wYEDIttlmm1w9cuTIMKaW86RpWn311UO20UYb5erUGps5c2bI/vrXv1ZvYlRF6j1ksU9XlsX3fakeE0OHDg1Zmc+CzrL0ubq4XrMsy0455ZQGj3XjjTeGLPWcbGpjpZVWytUPPfRQGJO6f0qtgaLU/VPqd7vFFlvk6lSPiYsvvjhk+jEtHlK9tPr06ZOri5+fZVmWvf/++yF74oknQlb8bC/V7ybVj67YY2LWrFlhTOo8mlr7+jg1PanfU7HXSOrzsVT/3uJ5Msvimk19VpKaQ/H9buo+LvW+JnW+69q1a65O3UuuvfbaIevdu3euTp1zx44dG7Ja8Y0JAAAAAACgNDYmAAAAAACA0tiYAAAAAAAASmNjAgAAAAAAKE2TaX6dahZTbPw3fvz4MOaaa64J2c0335yrU02XUo0yUw1xitkKK6wQxqyyyiohGzFiRK5ONSTr1KlTyM4444yQff/738/VqYZRqYahxUYrGvLUTvG/ber3nWrClGqis/766+fq0047LYzp3r17yIpNc1IN9TRwZVF873vfC1m/fv1ydaop0yeffFKzOVG+Qw89NFenmmxVqniu/Ne//hXGvPrqqyH79NNPc3WPHj3CmDXXXDNkqbkWGyun7jWuvPLKkLmm1kbqPuuoo47K1anG0IMHDw7Zl19+Wb2JVSDV4G6zzTYLWa9evXJ1qumd9dW8pdbKBRdcELJ27do1eKx//OMfIZs2bVrjJkbVFH/HO+64YxiTahZdPL+99dZbYcyMGTNCVstzRqrpes+ePUN2/fXXh6zYNPmVV14JY+68886Qpd7bsujatm0bslNPPTVXr7HGGhUdK/V+d8yYMbn6oosuCmM22WSTkO20007/dU5ZlmVffPFFyP7yl780OE9qq/i5Wt++fcOYgw8+OGTFc8Gzzz4bxqTOdal7wLK5R2t6Up/vpt4L/ulPf8rV66yzThiTasQ+ffr0kD3yyCO5+p133gljis2psyzLXn/99VxdfF+bZel1nmrUXXyP1KZNmzAmlRU/Y07NM/WeOHXerwbfmAAAAAAAAEpjYwIAAAAAACiNjQkAAAAAAKA0NiYAAAAAAIDSNJnm15VINZmZM2dORVljFRuXjR49Oox58803Q1aca6rJXar51GeffRayAQMG5OoPP/wwjBk+fHiDc6C+Uk10ir/bLIvNvlLNWlONoG688cZcPXTo0IWdIvw/qXNW//79Q1ZszDls2LAwJtXYlcVD6jp1yCGH5Oqll166omOlmng99dRTufrnP/95GDNu3LiQFZtipuaZatZ+9dVXh6x4jj333HPDmJVWWilkp59+eshYOKnzTLEZeZZlWbdu3XJ1qhlbqnlq2Q0SU433tttuu5Atu+yyuTp1D/f1119XbV40PalGhOutt16Dr0ut6ZNOOqkaU6LKitelgw46KIzp0qVLyIqNy9dff/0w5uGHHw7Z7NmzQ1bJ+9GUli1b5urevXuHMbfcckvIvvvd74Zs0qRJufrEE08MY7766quK5sWiSzUmTl2nisaOHRuyv/71ryG78sorc3WqYewKK6wQso4dO+bq1PV0jz32CNmtt94aMtfPchXvkVP3Y8Xfb5Zl2UMPPZSrm2qja+ovde0qZj169AhjbrvttpCtscYauTp1rkl9dvHnP/85ZJdcckmuTl2HK7nupubwne98J2S77rpryIp/f8Xrd5alPxdeZpllcvXcuXPDmOL77VryjQkAAAAAAKA0NiYAAAAAAIDS2JgAAAAAAABKY2MCAAAAAAAozWLV/LoeqtVAOnWcVMPQVOO7YsOUVPPrKVOmNH5ylKLYJDjLsmyjjTYKWbGBzVJLxf3Dxx9/PGS/+c1vFmF2kJdadzvttFPI5s2bl6vvu+++MKZa51HKl2p42a9fvwZfl2o8+Le//S1kRx11VK5ONRurZP2kft7rr78esn/84x8hW3PNNXN16lx9zDHHhOyGG27I1Z9++mmD8ySvffv2Idtkk01CVmzIlmq4OXLkyOpNrJGKTbqzLN1otHhfN2TIkDCmeG6leenUqVPIunfvHrLi+e+LL74IY1LN06m/YpP71O831Siz+P5w4MCBYcwRRxwRsrfffrvB46fOuRMnTgxZsSn3L3/5yzBmnXXWCdmsWbNCduONN+bqjz76KIxxn1gbqXv5nj17hmzq1Km5+qWXXgpjrrrqqpCl3o8W78eWW265MCbVbLvYsHXOnDlhzJdffhmy1L+Rcp122mm5uthcOMvS57ri2nAe4Nuk1kbxb3/99dcPY1ZZZZWQFa+xqfvtsWPHhiz1PrZ4vks1uk6do4pzSDW6vuiii0K24YYbhqx169YNziHV2Pq5557L1aNHjw5jyvybdCYHAAAAAABKY2MCAAAAAAAojY0JAAAAAACgNHpMlCT1bLF99tknZKln8o0fPz5XX3/99WFM6rlhNC09evQI2QYbbBCy4vMWZ8yYEcbcfffdIUs9ixMaK/VM2NSz3ydMmJCrb7311lpNiTpIPQe4TZs2uTrV3yHVy+Hoo48OWer81hipZ2CmrouDBw8O2ZFHHpmri/++LEv3ndh8881ztR4TCy/Vf2HFFVcMWbF/ROo8M3/+/OpNrJH23HPPkKXWTrEv2JNPPhnGeNZy87btttuGrEOHDiErruvUM471I2maij2TXnjhhTCmc+fOISuug2KviizLshNOOCFkrVrFt/XF5/anrrlvvvlmyCZPnpyrV1tttTAmdc5N9bn4wx/+kKut1/KknjVe/N1mWZa99dZbufr9998PY1LrJHWdWmaZZXL19ttvH8akrvPF/hHjxo0LY4YNGxay1D2b98S1k1pTxZ6ZqT6qqc/Civ1znnrqqTDG+YJvU7wGpfqYpK5TxfNW6n1sKkt9djtmzJhcveqqq4Yxqb4+xSzVsyn1WUzq76j4N5n6m/nggw9Cds455+TqVJ/HMvnGBAAAAAAAUBobEwAAAAAAQGlsTAAAAAAAAKWxMQEAAAAAAJRG8+uSpJqeHHHEESFLNW256KKLcrUGm01fqunTYYcdFrIBAwY0eKw33nijogwWRbFx0i677BLGpBowPvDAA7l67Nix1Z0YpSk2ycyyLNt6661DVmy8lWqmee6554Zs+vTpjZ9cI6SaMqbWZ/G6m2pAmzpWsSlZqiFZU2jI3JQUzzOpe6P27duH7KOPPsrVqcbmZevYsWPIfvrTn4Ys1UCv2ODRebP5K94XHnrooWFM6hxcPD/ddddd1Z0YNTNt2rRcfd5554UxDz74YMjWW2+9XJ16r5Bqnt6uXbuQffPNN7l61KhRYUyqYXWxOXFqbU6ZMiVkV199dcjGjx8fMsqRundJrYF33nknV/ft2zeM2XzzzUOWas665ZZb5uoNN9wwjGnbtm3IXnzxxVw9adKkMCbV6Lp///4hGzJkSK5O/XegcVL/LSdMmJCrU/e+qXPIfvvtl6sHDx4cxhTXZpZpiM3/p7gWn3322TDm9ttvD9nee++dq4vXySzLss6dO4fspJNOClmrVvmP01PrvDgmNS71HjIl9fc3Z86cXP3Pf/4zjDn88MNDNmzYsAaPXSbfmAAAAAAAAEpjYwIAAAAAACiNjQkAAAAAAKA0NiYAAAAAAIDSaH5dI8UmJ7/61a/CmGJzsyzLsuHDh4fskUceydWaaTZ9Z5xxRshSzc5bt24dss8//zxXX3HFFWHMF198EbJKGtYUG49W+jqav2JDueOPPz6MSTUvvvHGG3O1hmSLr9T5qHfv3iErnkdSTcMae46qptS/J9XMu9hsOTXP1L+xeL12Ll14qf9mqevUaqutlqu33377MKZ4r5RlsXFw6memfl6qCV1xPe25555hzFprrRWylCeffDJXpxpk07x07do1V6catqbu74uN0T/88MPqTozSTJ06NWTPPPNMyIoNPFPno2Iz9W/Lik0xU+fc4jUwy7Ls9NNPb/B1qXvC5557LmTet9ZP6r/9xIkTQ1ZcA7vttlsYk2qe2rFjx5AV12txDWZZln3wwQche/XVV3N1jx49wpjdd989ZFtttVXIDjjggFydavhN9dx22225OnWPlron79mzZ66+//77w5h77703ZI8++mjI3n333Vydaji86667hqz4eVzqHPbZZ5+F7I033giZe7n6mjVrVshOPPHEkJ111lm5ervttgtjUtnAgQMbnEP37t1DlrrGLrPMMg0eKyX1vmbQoEG5+swzzwxjJk+e3KifVybfmAAAAAAAAEpjYwIAAAAAACiNjQkAAAAAAKA0ekzUSN++fXP1/vvvH8aknhl60003hWzatGnVmxg1sfnmm+fqVE+R1LNfU8/CO//883P1Sy+9FMaknuNfXE+pZzmmnhE7d+7ckLHk6dOnT65O9RZInYs++eSTms2JcqWeRdypU6dGva5ly5ZVmdO3KR6/Q4cOYcwmm2wSspNPPjlkxf4qqfNksfdPlmXZyy+/3ODryCv+N/rnP/8ZxqSe27vhhhvm6tTvcccddwzZzJkzK8qKUtfm4nX3yCOPDGOKaynL0v1JRowY0eAcaF423XTTXJ16vnBqrRT7kaTWJs1L8TyZuudPrYPGro3U8YvX1Hbt2oUxqf4YY8aMadQcKE/qGeUPPPBArt54443DmFSPrtR9T7GnROp9wi233BKyoUOH5uqDDz44jEm9ly72KciyLDv00ENz9SWXXBLG6AdQPc8//3yuTvUQSfXgKvaBWGmllcKYY489NmTHHXdcyFL9whr6eVkW13Bx7WRZ+rOSYk+ULMuyvffeO1f7DK/+Uueor776Klen+pgMHjw4ZKnP1or3/f369QtjUj0fiv1yKukRlWVZdt5554Xs8ssvz9WL67nNNyYAAAAAAIDS2JgAAAAAAABKY2MCAAAAAAAojY0JAAAAAACgNJpfV0GqEcpdd92Vq1ONOUeNGhWyG264IWQaajYtqablxaY5qSZxqaaGqWY7d955Z66utIFNsaFTx44dw5his596SP33S1l22WVz9ZQpU2owmyVTqkHYtttum6tT62f48OEhmzFjRtXmRX2lrjWpRsHFv+HU+W655ZYLWarhbyXXt1Qj7dVWWy1Xn3DCCWHMDjvsELJik/csi/+e1Ln6tttuC9mECRPiZFkokyZNCtl1110XslNPPTVXr7HGGmFM//79Q1a8jmRZXE8TJ04MYz7++OOQFRvcde7cOYxJXd9S51trp3lLNdg87LDDcnWqUfr06dND9n/+z//J1alGxbAounbtGrJiE9fUtfrSSy8N2fz586s3MUpTvD875phjwpjVV189ZJtttlnIiveE7777bhjzwgsvhKx4bks1Dk7dM+y0004hK94jLLPMMmFM2e8ri/cHCxYsaDaf8YwbNy5XF693WZZl5557bsiKTdZT56LUtbKSRtcpqfNT8XeQ+nmpLLX2zz777Fx9zjnnhDGphsY0Pam/zVQT9GI2evToMKZv374hK54PUuvi6quvDtlll10WstT71sWRb0wAAAAAAAClsTEBAAAAAACUxsYEAAAAAABQGhsTAAAAAABAaTS/XkipZjuHHnpoyNZee+1cnWq2c/LJJ4ds6tSpizA7ytC9e/eQFRsFp37fqQabv/vd70JWSQObVIPNpZdeusE5pKTWdGObcRWbiqaajaWaQqaaCRWbfhfn2VwahtVD6ndebBScajj85Zdfhiz1u2PxlDqvpJqxFtdP6m96m222Cdl7770XsmKzw9QcUg2rf//73+fqzTffPIyppPFxlsVz5bBhw8KYa6+9NmSa0C661H/DN954I2RHHXVUrk5dh7/zne+ELHUN6tChQ67+4IMPwpjUut9oo41ydarxYfHYWZb+N06ePDlkNB/LLbdcyIrnqNS5LtXY9e23367avKBt27Yhu/LKK0PWrVu3XD1q1KgwxtpsPor3QV999VUY89Zbb4Xs448/Dln79u1zdep6OmvWrJAV39elmmbfdNNNIevXr1/IOnfunKtXXHHFMCb1b6xl8/bm3Bi++NnF0KFDw5i99947ZKuuumquPvHEE8OYAw88MGSpa2xx/aQ+T0k1VC+u19Q5MvW+uXXr1iHbdNNNc3Xx86EsS79v9pnG4qu4XoYMGRLG9O7du8HjvPDCCyE766yzQtZcGl2n+MYEAAAAAABQGhsTAAAAAABAaWxMAAAAAAAApbExAQAAAAAAlEbz64W0wgorhOzCCy8MWbHBZqrp54MPPli9iVGaVEPVYnPLYuPmLMuyESNGhCzVrDPV/LAo1fSpR48eDb5u9OjRIUs1gio21kk1aVxjjTVCtskmm+TqnXfeOYy55557QvbZZ5+F7J133snVc+bMydULFizQfLaR2rVrF7KBAwfm6tTv/Omnnw5Zc27mtqRJnbfef//9kK277rq5OrVW9t9//5Clzj/FxsPf//73w5jDDz88ZOutt16uXnrppcOYVLO6VIO5YiPivfbaK4yZOHFiyKiN1DmleJ1KXbdS15HUGihmqZ+Xel3xGjRmzJgwJtWUe8aMGSFrzs3rSJ/HUvdtRU888UTIZs+eXY0psYRq06ZNrt5vv/3CmOK9e5bF8+KHH34YxrgHX7KkrpUzZ85sMGvsOkm9LnUf+dFHH4Ws+P5zl112CWNGjhwZstT1moWXutdO/T6HDRuWq0877bQw5vLLLw/ZvvvuG7LNN988V/fq1SuM6datW8g6deoUsqLU2k81dR8+fHiuTjXIrvS9CU1P6vdZPP+sssoqFR2r+N7zJz/5SRizpN3/+cYEAAAAAABQGhsTAAAAAABAaWxMAAAAAAAApdFjogHFZ3OeeeaZYUzqeXXF584dcMABYYxncy6epkyZErIJEybk6pVWWimM6d+/f8geffTRkBWfPZ16FvXUqVNDVlxzn3/+eYPHzrL0s9mLz5rv3bt3GNO5c+eQFZ/TmHpmYuoZ3JdccknIis/oSz1XlMbZbrvtQlbsnZJaKw8//HDN5kT9pZ6hetVVV4Vs9913z9UdOnQIYwYMGBCym2++ucE5pPpVtGoVb1VS44pS/57UeWTHHXfM1annFdP0pa43jX1ub+p1X331Va5O9ZhYffXVQ/bll1+GLNUjg+Yj1V+r+Fzp1DX2xhtvDJlnT7Mois9ZX2eddcKYZZZZJmTFZ+2/8sorYUzqOqzvWPNVad+AWpo7d27IUvdsxb4pqXvS5ZdfPmR6TNRX6veb+jzj6quvDlnx95n63CX1GUTxPJbqAZF61v8XX3wRssGDB+fq4n0ji49iv+Asy7Lbb789ZJX0lEidJ7fffvtcPWrUqIWYXfPkGxMAAAAAAEBpbEwAAAAAAAClsTEBAAAAAACUxsYEAAAAAABQGs2v/0OqwWaxMclBBx0UxqQa2F1zzTW5+oMPPljE2dFUTJo0KWR/+ctfcvXZZ58dxrRu3bqirBLFJtNZFhtWFxveZVm6+c6sWbNC1rZt21ydagCUMnPmzP9aZ1mWffLJJyF75JFHQjZ58uSKfib/Xao54f/6X/8rZMVmX6l1Pnz48KrNi8XD0KFDQ/boo4/m6h//+MdhTOqckbrGVkuqYd5rr70WstRciw3sNJslZemll87VqfWcWjupc2mquSKLp9Tvcv311w9ZsSlwqnl6qokrLIrifX/xPPZtiu8p1l577TAm1Uh29OjRCzE7WDjFdZllWfbcc8+F7Ec/+lGuTjUh7tu3b8jGjh2bq1P3lqnrvPvGcqXWQbF5cOpcl3pPXJT6rCS1Du6///6Qvf7667k61TQ7pZJ7QmusdlLvWXffffeQ7bDDDg0eK/V7uuOOO0KWeo+6pPONCQAAAAAAoDQ2JgAAAAAAgNLYmAAAAAAAAEpjYwIAAAAAACjNEtv8OtX8Zuuttw7ZlVdemas7d+4cxqSa+V5wwQW5WsOa5iPV7PzSSy/N1ammz2eeeWbIUuup2CBxzpw5YUyxOVeWZdm//vWvXL3iiiuGMV9++WXI3nnnnZAVmzBNnDixojm89957uTrV9DPVGG/GjBkh8zdTHcsuu2zIVl555ZAVm329+eabYUyqUTrNW6oJ3LHHHpurBw4cGMb06tUrZI1t+Fs8J2ZZPLfceuutYcx5550XsmnTpoXMuYai1FpdYYUVcvXqq69e0bFS18FU40YWT6m10q5du5AV7x2nT58exqTu92BRjB8/Pld36NAhjGnbtm3Iio1jU++R11hjjZCNGzcuZKn7CGiM1P1a6r3tU089latT19zUe6FNN900V7/99tthzNSpU0NmjZcr9VlMsRn1KaecEsak1kHxGp469pAhQ0J29dVXh6y4FlPvX2h6unXrFrIrrrgiZO3btw9Z8Xec+nzs8MMPX4TZLTl8YwIAAAAAACiNjQkAAAAAAKA0NiYAAAAAAIDSLLE9JlLP07z88stDtuqqq+bqVO+Ayy67LGSpZ8fSfM2dOzdXp55LV+xXkmWebU7tFddmlmXZo48+GrLi89JTz+f3rEyyLD5fd+211w5jjjnmmJDtuuuuIWvTpk2u/uKLL8KY1HotPkt2ypQpYYzzK42V6hvQsmXLXD1y5MgwJrXmUs8m1mOi+Uj1rPv4449D1rt371w9YsSIMMY1lmorvh9N9Yzr2LFjyIrnwNRz9VO97FLP4C7OwbWZakr1Drvjjjty9Q9+8IMwJnWdL/YXaNUqflTmPN00Fe/JdthhhzDmuOOOC1nxGv7AAw+EMa+++mrIUuuuWmujsT35aJzU+9PU9S31e5k9e3au/tnPfhbGuOevjG9MAAAAAAAApbExAQAAAAAAlMbGBAAAAAAAUBobEwAAAAAAQGmW2ObXqcaca621VsiKDXFSDTbvvffeqs2L5kuzN+ph5syZITvggANCVmzopLkblUqtscsuu6yiDJqi1Pnvk08+ydVXXHFFGJNqBD9o0KCQzZs3bxFmR1NSbJaaZVl2zjnnhGzSpEm5+sorrwxj5syZU7V5QZbF9x4XX3xxGDNgwICQrbHGGrn6ySefDGNGjx4dsrlz5zY4B6im1PW62OT9lVdeCWPatGkTsrFjx+bqVNNa63nx8PHHH4fsF7/4RR1msvCssdpq3759rj7hhBPCmNatW4csda556aWXcvUTTzyxiLNbcvnGBAAAAAAAUBobEwAAAAAAQGlsTAAAAAAAAKWxMQEAAAAAAJRmiWh+3bZt25BttdVWISs2us6y2HxmzJgxYcyMGTMaPzmAkqWaamm0BfDtik1dH3zwwTDm4YcfDlmqOTLN24cffhiyY445Jle75lIPU6dODdmOO+4YsmWXXTZXp5paz549O2Sp5qBQtuL5ddy4cWFMaq0WXzdv3rzqTgwoVerz3X79+uXqHj16hDFz5swJ2ZQpU0J29NFH52rnjMbzjQkAAAAAAKA0NiYAAAAAAIDS2JgAAAAAAABKY2MCAAAAAAAozRLR/LpDhw4ha9myZchSTbxatcr/J7rnnnvCGI0NAQCWHKnGmRq/8m00u6apSp23Uk0+YXGVakjbokWLisYBi6/U9W38+PG5+qOPPgpjOnbsGLL7778/ZCNHjmz85MjxjQkAAAAAAKA0NiYAAAAAAIDS2JgAAAAAAABKs0T0mJg4cWLIdt5555C1bt06ZEstld+7mTNnTvUmBgAAAEDV6R0B/P9Gjx6dqzfbbLM6zYT/5BsTAAAAAABAaWxMAAAAAAAApbExAQAAAAAAlKbRPSYWLFhQzXk0Cal/U3P8d9ZKrf9b+V2QYt1RtjLWhHVHkXMd9WDdUTbXWOrBuY56sO4om2ss9dDQmmj0NyamTZvW2Jc2Wd98803439y5c3P/49vVek00xzXHorPuKFsZa8K6o8i5jnqw7iibayz14FxHPVh3lM01lnpoaE20WNDI7az58+dno0ePzjp27Ji1aNGiUZOjeViwYEE2bdq0bOWVV86WWqp2Twez5vhP1h1lK2vNZZl1x78511EP1h1lc42lHpzrqAfrjrK5xlIPla67Rm9MAAAAAAAALCzNrwEAAAAAgNLYmAAAAAAAAEpjYwIAAAAAACiNjQkAAAAAAKA0NiYAAAAAAIDS2JgAAAAAAABKY2MCAAAAAAAojY0JAAAAAACgNDYmAAAAAACA0tiYAAAAAAAASmNjAgAAAAAAKI2NCQAAAAAAoDT/F7z6x6mIkjG6AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 2000x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "# Cargar los datos de MNIST y dividirlos en conjuntos de entrenamiento y prueba\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "# Preprocesar los datos: aplanar las imágenes y normalizar los valores de píxeles\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), -1))\n",
    "x_test = x_test.reshape((len(x_test), -1))\n",
    "\n",
    "# Definir la arquitectura del autoencoder\n",
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(128, activation='relu')(input_img)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "# Crear el modelo del autoencoder\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# Compilar el modelo\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Entrenar el autoencoder\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "\n",
    "# Obtener las imágenes reconstruidas del conjunto de prueba\n",
    "reconstructed_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "# Visualizar algunas imágenes originales y reconstruidas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # número de imágenes a mostrar\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Imagen original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Imagen reconstruida\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(reconstructed_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizando el vector Latente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "235/235 [==============================] - 4s 14ms/step - loss: 0.2452 - val_loss: 0.1688\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1511 - val_loss: 0.1374\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1304 - val_loss: 0.1223\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1195 - val_loss: 0.1143\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1134 - val_loss: 0.1098\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1091 - val_loss: 0.1057\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1057 - val_loss: 0.1030\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1033 - val_loss: 0.1011\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1012 - val_loss: 0.0990\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0994 - val_loss: 0.0974\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0976 - val_loss: 0.0959\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0962 - val_loss: 0.0943\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0949 - val_loss: 0.0933\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0938 - val_loss: 0.0923\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0929 - val_loss: 0.0918\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0922 - val_loss: 0.0906\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0913 - val_loss: 0.0903\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0906 - val_loss: 0.0898\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0900 - val_loss: 0.0890\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0895 - val_loss: 0.0889\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0889 - val_loss: 0.0882\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0885 - val_loss: 0.0874\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0881 - val_loss: 0.0870\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0877 - val_loss: 0.0869\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0874 - val_loss: 0.0865\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0870 - val_loss: 0.0860\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0867 - val_loss: 0.0856\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0864 - val_loss: 0.0857\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0861 - val_loss: 0.0855\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0858 - val_loss: 0.0851\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0856 - val_loss: 0.0848\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0853 - val_loss: 0.0846\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0850 - val_loss: 0.0842\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0848 - val_loss: 0.0842\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0845 - val_loss: 0.0838\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0843 - val_loss: 0.0838\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0841 - val_loss: 0.0838\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0839 - val_loss: 0.0833\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0837 - val_loss: 0.0831\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0836 - val_loss: 0.0829\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0833 - val_loss: 0.0828\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0832 - val_loss: 0.0828\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0830 - val_loss: 0.0826\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0829 - val_loss: 0.0823\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0827 - val_loss: 0.0823\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0826 - val_loss: 0.0824\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0824 - val_loss: 0.0821\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0823 - val_loss: 0.0818\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0822 - val_loss: 0.0817\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0821 - val_loss: 0.0820\n",
      "1875/1875 [==============================] - 1s 751us/step\n",
      "313/313 [==============================] - 0s 796us/step\n",
      "Epoch 1/10\n",
      "235/235 [==============================] - 1s 1ms/step - loss: 5.2902 - accuracy: 0.1560 - val_loss: 2.9714 - val_accuracy: 0.2885\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 0s 822us/step - loss: 2.0419 - accuracy: 0.4447 - val_loss: 1.3248 - val_accuracy: 0.5943\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 0s 861us/step - loss: 1.1059 - accuracy: 0.6586 - val_loss: 0.8420 - val_accuracy: 0.7306\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 0s 822us/step - loss: 0.7718 - accuracy: 0.7563 - val_loss: 0.6336 - val_accuracy: 0.7962\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 0s 806us/step - loss: 0.6138 - accuracy: 0.8049 - val_loss: 0.5256 - val_accuracy: 0.8298\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 0s 809us/step - loss: 0.5268 - accuracy: 0.8352 - val_loss: 0.4677 - val_accuracy: 0.8520\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 0s 901us/step - loss: 0.4756 - accuracy: 0.8517 - val_loss: 0.4289 - val_accuracy: 0.8670\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 0s 803us/step - loss: 0.4430 - accuracy: 0.8635 - val_loss: 0.4047 - val_accuracy: 0.8727\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 0s 841us/step - loss: 0.4212 - accuracy: 0.8704 - val_loss: 0.3904 - val_accuracy: 0.8787\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 0s 809us/step - loss: 0.4054 - accuracy: 0.8754 - val_loss: 0.3792 - val_accuracy: 0.8829\n",
      "313/313 [==============================] - 0s 508us/step - loss: 0.3792 - accuracy: 0.8829\n",
      "Pérdida de clasificación: 0.3792390525341034\n",
      "Exactitud de clasificación: 0.8828999996185303\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Cargar los datos de MNIST y dividirlos en conjuntos de entrenamiento y prueba\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocesar los datos: aplanar las imágenes y normalizar los valores de píxeles\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), -1))\n",
    "x_test = x_test.reshape((len(x_test), -1))\n",
    "\n",
    "# Definir la arquitectura del autoencoder\n",
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(128, activation='relu')(input_img)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "latent = Dense(32, activation='relu')(encoded)\n",
    "decoded = Dense(64, activation='relu')(latent)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "# Crear el modelo del autoencoder\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# Compilar el modelo\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Entrenar el autoencoder\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "\n",
    "# Obtener el vector latente (representación codificada)\n",
    "encoder = Model(input_img, latent)\n",
    "encoded_train = encoder.predict(x_train)\n",
    "encoded_test = encoder.predict(x_test)\n",
    "\n",
    "# Convertir las etiquetas a codificación one-hot\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Definir la arquitectura del clasificador utilizando el vector latente como entrada\n",
    "input_latent = Input(shape=(32,))\n",
    "output = Dense(10, activation='softmax')(input_latent)\n",
    "\n",
    "# Crear el modelo del clasificador\n",
    "classifier = Model(input_latent, output)\n",
    "\n",
    "# Compilar el modelo del clasificador\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el clasificador utilizando el vector latente como características de entrada\n",
    "classifier.fit(encoded_train, y_train,\n",
    "               epochs=10,\n",
    "               batch_size=256,\n",
    "               validation_data=(encoded_test, y_test))\n",
    "\n",
    "# Evaluar el rendimiento del clasificador en el conjunto de prueba\n",
    "loss, accuracy = classifier.evaluate(encoded_test, y_test)\n",
    "print(\"Pérdida de clasificación:\", loss)\n",
    "print(\"Exactitud de clasificación:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
